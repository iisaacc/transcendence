# logstash.conf

input {
  beats {
    port => 5044
    ssl => true
    ssl_certificate => "/usr/share/logstash/config/certs/cert.pem"
    ssl_key => "/usr/share/logstash/config/certs/key.pem"
  }
}


# Filter section: Process and parse logs
filter {
  # Check if the log is NGINX based on a recognizable pattern
  if [message] =~ /^\d+\.\d+\.\d+\.\d+ - .* \[.*\] ".* HTTP\/\d\.\d" \d+ \d+/ {
    # GROK pattern for parsing NGINX logs (common combined format)
    grok {
      match => {
        "message" => '%{IPORHOST:client_ip} - %{DATA:ident} %{DATA:auth} \[%{HTTPDATE:log_timestamp}\] "%{WORD:method} %{DATA:request} HTTP/%{NUMBER:http_version}" %{NUMBER:status} %{NUMBER:bytes_sent} "(?:%{URI:referrer}|-)" "(?:%{DATA:user_agent}|-)"'
      }
      overwrite => ["message"]
      add_tag => [ "nginx", "status_%{status}" ]
    }

    # Parse the timestamp field from logs
    date {
      match => ["log_timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
      target => "@timestamp"
      remove_field => ["log_timestamp"]
    }

    # Add tags for error categories
    if [status] =~ /^5\d{2}$/ {
      mutate {
        add_tag => ["server_error"]
      }
    }
    if [status] =~ /^4\d{2}$/ {
      mutate {
        add_tag => ["client_error"]
      }
    }
  }
  # Check if the log is Django based on a recognizable pattern
  else if [message] =~ /^(DEBUG|INFO|WARNING|ERROR|CRITICAL) \d{4}-\d{2}-\d{2}/ {
    # GROK pattern aligned with the standardized Django log format
    grok {
      match => {
        "message" => "%{LOGLEVEL:log_level} %{TIMESTAMP_ISO8601:log_timestamp} %{DATA:module} %{GREEDYDATA:log_message}"
      }
      overwrite => ["message"]
      add_tag => [ "django", "%{log_level}", "%{module}" ]
    }

    # Parse the timestamp field from logs
    date {
      match => ["log_timestamp", "ISO8601"]
      target => "@timestamp"
      remove_field => ["log_timestamp"]
    }

    # Optionally, tag errors for easy filtering
    if [log_level] == "ERROR" {
      mutate {
        add_tag => ["error"]
      }
    }
  }
  # Check if the log is Uvicorn based on the presence of recognizable patterns
  else if [message] =~ /^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3} [A-Z]+ .*/ {
    # GROK pattern aligned with Uvicorn's log format
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:log_timestamp} %{LOGLEVEL:log_level} %{GREEDYDATA:log_message}"
      }
      overwrite => ["message"]
      add_tag => [ "uvicorn", "%{log_level}" ]
    }

    # Parse the timestamp field from logs
    date {
      match => ["log_timestamp", "ISO8601"]
      target => "@timestamp"
      remove_field => ["log_timestamp"]
    }

    # Optionally, add tags based on the log level for better categorization
    if [log_level] == "ERROR" {
      mutate {
        add_tag => ["uvicorn_error"]
      }
    } else if [log_level] == "INFO" {
      mutate {
        add_tag => ["uvicorn_info"]
      }
    } else if [log_level] == "WARNING" {
      mutate {
        add_tag => ["uvicorn_warning"]
      }
    }
  }
  # If the log doesn't match any pattern, add an "unmatched" tag
  else {
    mutate {
      add_tag => ["unmatched"]
    }
  }
}

# Output section: Send processed logs to Elasticsearch
output {
  elasticsearch {
    hosts => ["https://elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    ssl => true
    cacert => "/usr/share/logstash/config/certs/cert.pem"
    user => "elastic"
    password => "${ELASTICSEARCH_PASSWORD}"
  }
}
